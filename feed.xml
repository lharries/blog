<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.2">Jekyll</generator><link href="/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="/blog/" rel="alternate" type="text/html" /><updated>2018-03-02T18:55:16+00:00</updated><id>/blog/</id><title type="html">Luke Harries</title><subtitle>Working to improve the internet for the millions with visual impairments at Visual Cognition. MSc Computer Science at UCL. Cambridge Medicine.</subtitle><entry><title type="html">The hidden power of Hacker News Search</title><link href="/blog/hn-search/" rel="alternate" type="text/html" title="The hidden power of Hacker News Search" /><published>2018-03-02T16:00:00+00:00</published><updated>2018-03-02T16:00:00+00:00</updated><id>/blog/hn-search</id><content type="html" xml:base="/blog/hn-search/">&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://hn.algolia.com/&quot;&gt;Hacker News Search&lt;/a&gt; is my go-to search engine.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/&quot;&gt;Hacker News&lt;/a&gt; (HN) is fantastic for keeping you up to date with the latest advancements in startup and tech; submitted, ranked and commented on by people all over the world. However, with search, it becomes much more powerful.&lt;/p&gt;

&lt;p&gt;Here’s what it is great for:&lt;/p&gt;

&lt;h3 id=&quot;finding-the-best-resources-for-learning-a-new-technology&quot;&gt;Finding the best resources for learning a new technology&lt;/h3&gt;

&lt;p&gt;As engineers, we need to rapidly learn new technologies, languages, and skills. However, finding the best resources to learn from is hard. HN Search solves this.&lt;/p&gt;

&lt;p&gt;For example, if you are wanting to learn &lt;a href=&quot;https://hn.algolia.com/?query=natural%20language%20processing&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=all&quot;&gt;Natural Language Processing&lt;/a&gt;, &lt;a href=&quot;https://hn.algolia.com/?query=data%20science&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=all&quot;&gt;Data Science&lt;/a&gt;, or even &lt;a href=&quot;https://hn.algolia.com/?query=lstm&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=all&quot;&gt;LSTMs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/imgs/lstm.png&quot; alt=&quot;Searching for LSTMs on Hacker News Search&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;finding-the-top-recent-articles-for-a-topiccompany&quot;&gt;Finding the top recent articles for a topic/company&lt;/h3&gt;

&lt;p&gt;HN is great for the top articles in the last 24 hours. But sometimes you want to see the top articles for the &lt;a href=&quot;https://hn.algolia.com/?query=&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastWeek&amp;amp;type=story&quot;&gt;last week&lt;/a&gt;, &lt;a href=&quot;https://hn.algolia.com/?query=&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastMonth&amp;amp;type=story&quot;&gt;last month&lt;/a&gt; or &lt;a href=&quot;https://hn.algolia.com/?query=&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastYear&amp;amp;type=story&quot;&gt;last year&lt;/a&gt;. HN Search Solves this and lets you filter by topic too.&lt;/p&gt;

&lt;p&gt;For example, determining the state of &lt;a href=&quot;https://hn.algolia.com/?query=quantum%20computers&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastYear&amp;amp;type=all&quot;&gt;Quantum Computers&lt;/a&gt;, what the latest moves are by &lt;a href=&quot;https://hn.algolia.com/?query=amazon&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastYear&amp;amp;type=all&quot;&gt;Amazon&lt;/a&gt;, or finding top research on &lt;a href=&quot;https://hn.algolia.com/?query=crispr&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=pastYear&amp;amp;type=all&quot;&gt;CRISPR&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;getting-crowdsourced-opinions&quot;&gt;Getting crowdsourced opinions&lt;/h3&gt;

&lt;p&gt;It’s often useful to get opinions from people of varying backgrounds and locations. The comments section of HN is a great place for this. All you have to do is find the relevant article. This is where HN Search steps in.&lt;/p&gt;

&lt;p&gt;For example, if you are considering a Ph.D. and &lt;a href=&quot;https://hn.algolia.com/?query=phd&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=all&quot;&gt;wanting to hear the pros and cons&lt;/a&gt; or are thinking of learning machine learning with Fast.ai course and &lt;a href=&quot;https://hn.algolia.com/?query=fast.ai&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=all&quot;&gt;wanting hear from people who have completed it&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Hacker News Search is my go-to search engine.</summary></entry><entry><title type="html">Improving the internet for the visually impaired!</title><link href="/blog/hackathon/healthtech/2018/01/25/ai-screenreader.html" rel="alternate" type="text/html" title="Improving the internet for the visually impaired!" /><published>2018-01-25T17:49:12+00:00</published><updated>2018-01-25T17:49:12+00:00</updated><id>/blog/hackathon/healthtech/2018/01/25/ai-screenreader</id><content type="html" xml:base="/blog/hackathon/healthtech/2018/01/25/ai-screenreader.html">&lt;p&gt;&lt;em&gt;Originally written as a guest post for &lt;a href=&quot;https://microsoft.com/&quot;&gt;Microsoft&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;HackCambridge provided the perfect opportunity to return to Cambridge University. It is where I completed my undergraduate degree in Medicine and Cognitive Neuroscience, before moving to UCL to study a masters in Computer Science. Our team included &lt;a href=&quot;https://www.linkedin.com/in/filipkozera/&quot;&gt;Filip&lt;/a&gt;, a masters student in information engineering at Cambridge, where he is using deep learning on EMG signals to control prosthetics; &lt;a href=&quot;https://www.linkedin.com/in/marcin-kolaszewski-07912314a/&quot;&gt;Marcin&lt;/a&gt;, a joint honors Mathematics and Computer Science student from Brown University; and &lt;a href=&quot;https://www.linkedin.com/in/mateusz-jakub-staniszewski-19946590/&quot;&gt;Mateusz&lt;/a&gt;, a recent Mathematics graduate from Imperial and a current Software Engineer at BlackRock.&lt;/p&gt;

&lt;p&gt;With flights from Poland to London for two of the team members booked, we starting discussing ideas for what would be our first Hackathon together. Our ideas ranged from trying to implement a decentralised ICO (&lt;a href=&quot;https://ethresear.ch/t/explanation-of-daicos/465&quot;&gt;DAICO&lt;/a&gt;) to controlling a VR world with a &lt;a href=&quot;https://www.myo.com/&quot;&gt;Myo armband&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As the event neared, Microsoft released a video of their &lt;a href=&quot;https://www.youtube.com/watch?v=R2mC-NUAmMk&quot;&gt;Seeing AI app&lt;/a&gt; to announce their involvement as a keen sponsor. The video demonstrated how Saqid Shaikh, a visually impaired software developer at Microsoft, used the app he created, to convert a visual world into an audible experience. &lt;strong&gt;It was incredible&lt;/strong&gt;. The app could describe kids playing Frisbee in the park, or allow him to read a menu. We could only imagine the impact it had on him and many others with visual impairments.&lt;/p&gt;

&lt;p&gt;We knew we wanted to build on SeeingAI’s fantastic work. We initially discussed building an Android app equivalent, possibly in conjunction with the Myo Armband for hands-free control. However, with five minutes to go before the hackathon started and much excitement, it dawned on us how much of the internet was still inaccessible to the visually impaired in this day and age. We were committed to solving a problem which affects 32 million people worldwide in the hope of having a true social impact&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;People with visual impairments frequently rely on a Screen Reader to navigate the internet. The Screen Reader reads out the written content of each page. However, when the Screen Reader reaches an image it has to rely on the “alt tag” to provide a caption. For the majority of the internet these “alt tags” are either missing (think of any user-uploaded content such as Twitter or LinkedIn), superficial or inaccurate.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;This affects millions of people every day.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/HackCambridgeScreenReader/Blog/raw/master/job.png&quot; alt=&quot;Example of job post which is save as an image and therefore not accessible&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The Screen Reader would not pickup any details of this “Hot Job”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;p&gt;Once we had narrowed down the problem, coming up with the solution was much easier. We decided we would bring Facebook’s automatic “alt tag” generation to every page on the internet (right click on your profile picture, click “Inspect” to see what Facebook sees!).&lt;/p&gt;

&lt;p&gt;By using a Chrome extension we could scan through every element on the page looking for images lacking an “alt tag”. For each image where the “alt tag” was missing, we would send the image URL to an Azure cloud function. The cloud function would check if we already had the “alt tag” saved and if so return it. If not we would use the Microsoft’s Cognitive Services Vision API to perform object recognition and generate the description to be added as the “alt tag”.&lt;/p&gt;

&lt;p&gt;We split into pairs: Mateusz and I built the Chrome extension, and Filip and Marcin built the cloud function and connected it to the Cognitive Services API. We started programming at 2 pm and by 9 pm we already had a fully functional prototype. The speed, accuracy and ease of integration with which the image descriptions were being generated would not have been possible just a few years ago. The extra time allowed us to link in three more APIs: facial recognition, emotion recognition and OCR (image to text), depending on what was in the image. This provided much more descriptive image captions.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The speed, accuracy and ease of integration with which the image descriptions were being generated would not have been possible just a few years ago.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/HackCambridgeScreenReader/Blog/raw/master/example.png&quot; alt=&quot;example of a generated description&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=_JQYoQBfBpI&quot;&gt;Watch a demo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h3&gt;

&lt;p&gt;We are really proud of what we have built so far and cannot wait to release it to the public. We hope our Chrome extension will empower those with visual impairments to browse the web, without having to rely on others to create the “alt tags”.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/HackCambridgeScreenReader/Blog/raw/master/team.jpg&quot; alt=&quot;Team Picture&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;:boom: Thanks very much to &lt;a href=&quot;https://microsoft.com/&quot;&gt;Microsoft&lt;/a&gt; for the Cognitive Services prize!&lt;/em&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Originally written as a guest post for Microsoft</summary></entry><entry><title type="html">About Me</title><link href="/blog/luke/harries/2018/01/20/about-me.html" rel="alternate" type="text/html" title="About Me" /><published>2018-01-20T17:49:12+00:00</published><updated>2018-01-20T17:49:12+00:00</updated><id>/blog/luke/harries/2018/01/20/about-me</id><content type="html" xml:base="/blog/luke/harries/2018/01/20/about-me.html">&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/blog/assets/imgs/headshot.png&quot; alt=&quot;A picture of me looking happy with a blue background&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;I’m working on improving the internet for the millions of people with visual impairments at &lt;a href=&quot;https://visualcognition.co/&quot;&gt;Visual Cognition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’m also a Masters student in Computer Science at &lt;a href=&quot;http://www.ucl.ac.uk/&quot;&gt;UCL&lt;/a&gt; and working as a contract Machine Learning Engineer at &lt;a href=&quot;http://ccg.ai/&quot;&gt;Cambridge Cancer Genomics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I write code in Java, Python, and Javascript.&lt;/p&gt;

&lt;p&gt;Some of the things I’ve built include a proof-of-concept for a &lt;a href=&quot;https://danielquinn.org/blog/the-sudoimmerse-hackathon/&quot;&gt;faster, cheaper and more accurate test&lt;/a&gt; for macular degeneration. You can find more of my projects &lt;a href=&quot;/blog/projects&quot;&gt;here&lt;/a&gt; and the code on &lt;a href=&quot;https://github.com/lharries&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I previously co-founded &lt;a href=&quot;http://proteam.io/&quot;&gt;Proteam&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Proteam is a complete sports management system for Universities.&lt;/p&gt;

&lt;p&gt;Prior to that, I studied Medicine at &lt;a href=&quot;https://www.cam.ac.uk/&quot;&gt;Cambridge&lt;/a&gt;. Where I was President of the &lt;a href=&quot;https://www.cusus.org/&quot;&gt;Cambridge StartUp Society&lt;/a&gt; which hosted events by &lt;a href=&quot;http://tomblomfield.com/&quot;&gt;startup founders&lt;/a&gt; and &lt;a href=&quot;https://forwardpartners.com/&quot;&gt;venture capitalists&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’m always keen to hear about new projects or grab coffee, contact me at luke.harries@me.com&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>